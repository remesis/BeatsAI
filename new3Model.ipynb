{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1qrw5jhMh6dsxD89ANPuPh-xoJQ755lPZ",
      "authorship_tag": "ABX9TyN/40RHXw5DWfyblkE0deAc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/remesis/BeatsAI/blob/main/new3Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApqY8ksK6Esy"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow.keras as keras\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import math\n",
        "import librosa"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'cnn_7738_BeatsAI.keras'\n",
        "path = F\"/content/drive/MyDrive/SavedModels/{model_name}\""
      ],
      "metadata": {
        "id": "3Gk-GNo36TEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataDir = \"/content/drive/MyDrive/Data/genres_original\"\n",
        "jsonPath = \"/content/drive/MyDrive/Data/data.json\"\n",
        "csvPath = \"/content/drive/MyDrive/Data/features_30_sec.csv\""
      ],
      "metadata": {
        "id": "KZpl545R6Wk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(jsonPath, \"r\") as fp:\n",
        "  data = json.load(fp)\n",
        "\n",
        "X = np.array(data[\"mfcc\"])\n",
        "y = np.array(data[\"labels\"])"
      ],
      "metadata": {
        "id": "Cylhj7KP6buy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "ePvUO4nd6fCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelLSTM = keras.Sequential()\n",
        "\n",
        "\n",
        "modelLSTM.add(keras.layers.LSTM(64,input_shape = (X_train.shape[1], X_train.shape[2]), return_sequences=True))\n",
        "modelLSTM.add(keras.layers.LSTM(128, return_sequences=True,kernel_regularizer=keras.regularizers.l2(0.01)))\n",
        "modelLSTM.add(keras.layers.LSTM(64, return_sequences=True,kernel_regularizer=keras.regularizers.l2(0.01)))\n",
        "modelLSTM.add(keras.layers.LSTM(64))\n",
        "\n",
        "\n",
        "modelLSTM.add(keras.layers.Dense(128, activation='relu'))\n",
        "modelLSTM.add(keras.layers.Dropout(0.3))\n",
        "\n",
        "modelLSTM.add(keras.layers.Dense(64, activation='relu'))\n",
        "modelLSTM.add(keras.layers.Dropout(0.3))\n",
        "\n",
        "modelLSTM.add(keras.layers.Dense(32, activation='relu'))\n",
        "modelLSTM.add(keras.layers.Dropout(0.3))\n",
        "\n",
        "modelLSTM.add(keras.layers.Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "i1g1CQML6f10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelCNN = keras.Sequential()\n",
        "\n",
        "modelCNN.add(keras.layers.Conv2D(128, (3, 3), activation='relu', input_shape=(X_train.shape[1], X_train.shape[2], 1)))\n",
        "modelCNN.add(keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n",
        "modelCNN.add(keras.layers.BatchNormalization())\n",
        "\n",
        "modelCNN.add(keras.layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "modelCNN.add(keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n",
        "modelCNN.add(keras.layers.BatchNormalization())\n",
        "\n",
        "\n",
        "modelCNN.add(keras.layers.Conv2D(64, (2, 2), activation='relu'))\n",
        "modelCNN.add(keras.layers.MaxPooling2D((2, 2), strides=(2, 2), padding='same'))\n",
        "modelCNN.add(keras.layers.BatchNormalization())\n",
        "\n",
        "modelCNN.add(keras.layers.Flatten())\n",
        "\n",
        "modelCNN.add(keras.layers.Dense(64, activation='relu'))\n",
        "modelCNN.add(keras.layers.Dropout(0.2))\n",
        "\n",
        "modelCNN.add(keras.layers.Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "_y-JhuF86mzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "modelNN = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(X.shape[1], X.shape[2])),\n",
        "    keras.layers.Dense(2048, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)),\n",
        "    keras.layers.Dropout(0.1),\n",
        "    keras.layers.Dense(1024, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)),\n",
        "    keras.layers.Dropout(0.1),\n",
        "    keras.layers.Dense(512, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)),\n",
        "    keras.layers.Dropout(0.1),\n",
        "    keras.layers.Dense(256, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)),\n",
        "    keras.layers.Dropout(0.1),\n",
        "    keras.layers.Dense(128, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)),\n",
        "    keras.layers.Dropout(0.1),\n",
        "    keras.layers.Dense(64, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)),\n",
        "    keras.layers.Dropout(0.1),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "4m33KU6f6qk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelLSTM.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IitBWCA369T0",
        "outputId": "047f593d-a7dc-4807-b293-9422fdfaaed7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 130, 64)           19968     \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 130, 128)          98816     \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 130, 64)           49408     \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 64)                33024     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               8320      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 220202 (860.16 KB)\n",
            "Trainable params: 220202 (860.16 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelCNN.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGsiss387PUG",
        "outputId": "1be775eb-2b00-4491-dbe0-eeda59b6c5c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 128, 11, 128)      1280      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 64, 6, 128)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 64, 6, 128)        512       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 62, 4, 128)        147584    \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 31, 2, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 31, 2, 128)        512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 30, 1, 64)         32832     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 15, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 15, 1, 64)         256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 960)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 64)                61504     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 245130 (957.54 KB)\n",
            "Trainable params: 244490 (955.04 KB)\n",
            "Non-trainable params: 640 (2.50 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelNN.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nWwi7co7Z8X",
        "outputId": "92bf0a13-1168-45fa-80b5-2e5eabc09304"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_1 (Flatten)         (None, 1690)              0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 2048)              3463168   \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1024)              2098176   \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 512)               524800    \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6259274 (23.88 MB)\n",
            "Trainable params: 6259274 (23.88 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = keras.optimizers.Adam(learning_rate=0.0000000000001)\n",
        "modelNN.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "historyNN = modelNN.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=48, epochs=100)\n"
      ],
      "metadata": {
        "id": "T6cY9B-z7fku",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dac391f1-542a-4da9-8629-2659de9268cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "138/138 [==============================] - 8s 9ms/step - loss: 43.9077 - accuracy: 0.1063 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 2/100\n",
            "138/138 [==============================] - 1s 9ms/step - loss: 43.9645 - accuracy: 0.1043 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 3/100\n",
            "138/138 [==============================] - 1s 8ms/step - loss: 43.6994 - accuracy: 0.1104 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 4/100\n",
            "138/138 [==============================] - 1s 9ms/step - loss: 44.1375 - accuracy: 0.1040 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 5/100\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 44.0199 - accuracy: 0.1052 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 6/100\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 44.3706 - accuracy: 0.1057 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 7/100\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 44.2455 - accuracy: 0.1069 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 8/100\n",
            "138/138 [==============================] - 1s 6ms/step - loss: 43.6097 - accuracy: 0.1049 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 9/100\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 44.1697 - accuracy: 0.1033 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 10/100\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 44.0888 - accuracy: 0.1060 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 11/100\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 44.0977 - accuracy: 0.1049 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 12/100\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 44.1734 - accuracy: 0.1060 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 13/100\n",
            "138/138 [==============================] - 1s 6ms/step - loss: 44.3031 - accuracy: 0.1022 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 14/100\n",
            "138/138 [==============================] - 1s 6ms/step - loss: 43.9471 - accuracy: 0.1069 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 15/100\n",
            "138/138 [==============================] - 1s 8ms/step - loss: 44.3332 - accuracy: 0.1060 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 16/100\n",
            "138/138 [==============================] - 1s 9ms/step - loss: 44.4267 - accuracy: 0.1034 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 17/100\n",
            "138/138 [==============================] - 1s 9ms/step - loss: 44.0278 - accuracy: 0.1072 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 18/100\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 43.9252 - accuracy: 0.1125 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 19/100\n",
            "138/138 [==============================] - 1s 6ms/step - loss: 44.0807 - accuracy: 0.1052 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 20/100\n",
            "138/138 [==============================] - 1s 6ms/step - loss: 44.1314 - accuracy: 0.1051 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 21/100\n",
            "138/138 [==============================] - 1s 6ms/step - loss: 44.2303 - accuracy: 0.1061 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 22/100\n",
            "138/138 [==============================] - 1s 6ms/step - loss: 44.2319 - accuracy: 0.1060 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 23/100\n",
            "138/138 [==============================] - 1s 6ms/step - loss: 44.4979 - accuracy: 0.1046 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 24/100\n",
            "138/138 [==============================] - 1s 8ms/step - loss: 44.0376 - accuracy: 0.1090 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 25/100\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 44.0319 - accuracy: 0.1067 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 26/100\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 44.1459 - accuracy: 0.1081 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 27/100\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 44.4223 - accuracy: 0.1058 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 28/100\n",
            "138/138 [==============================] - 1s 8ms/step - loss: 43.9959 - accuracy: 0.1076 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 29/100\n",
            "138/138 [==============================] - 1s 9ms/step - loss: 43.8256 - accuracy: 0.1046 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 30/100\n",
            "138/138 [==============================] - 1s 9ms/step - loss: 43.8747 - accuracy: 0.1033 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 31/100\n",
            "138/138 [==============================] - 1s 9ms/step - loss: 44.1695 - accuracy: 0.1022 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 32/100\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 44.2733 - accuracy: 0.1043 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 33/100\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 44.0815 - accuracy: 0.1052 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 34/100\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 44.1635 - accuracy: 0.1054 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 35/100\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 44.2935 - accuracy: 0.1055 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 36/100\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 44.2214 - accuracy: 0.1039 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 37/100\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 43.8138 - accuracy: 0.1067 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 38/100\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 44.0134 - accuracy: 0.1086 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 39/100\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 43.9128 - accuracy: 0.1110 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 40/100\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 44.0941 - accuracy: 0.1075 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 41/100\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 44.0030 - accuracy: 0.1046 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 42/100\n",
            "138/138 [==============================] - 1s 9ms/step - loss: 43.9211 - accuracy: 0.1134 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 43/100\n",
            "138/138 [==============================] - 1s 9ms/step - loss: 44.3115 - accuracy: 0.1046 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 44/100\n",
            "138/138 [==============================] - 1s 9ms/step - loss: 44.2763 - accuracy: 0.1076 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 45/100\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 44.2630 - accuracy: 0.1087 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 46/100\n",
            "138/138 [==============================] - 1s 8ms/step - loss: 44.1982 - accuracy: 0.1102 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 47/100\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 44.3995 - accuracy: 0.1036 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 48/100\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 44.2770 - accuracy: 0.1092 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 49/100\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 44.0748 - accuracy: 0.1078 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 50/100\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 44.3865 - accuracy: 0.1079 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 51/100\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 44.3565 - accuracy: 0.1061 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 52/100\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 44.0697 - accuracy: 0.1052 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 53/100\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 44.2078 - accuracy: 0.0998 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 54/100\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 43.7026 - accuracy: 0.1117 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 55/100\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 43.6716 - accuracy: 0.1117 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 56/100\n",
            "138/138 [==============================] - 1s 9ms/step - loss: 44.0306 - accuracy: 0.1045 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 57/100\n",
            "138/138 [==============================] - 1s 9ms/step - loss: 43.8539 - accuracy: 0.1093 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 58/100\n",
            "138/138 [==============================] - 1s 10ms/step - loss: 44.2060 - accuracy: 0.1028 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 59/100\n",
            "138/138 [==============================] - 1s 8ms/step - loss: 44.3953 - accuracy: 0.1067 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 60/100\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 43.8738 - accuracy: 0.1070 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 61/100\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 43.8802 - accuracy: 0.1084 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 62/100\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 44.2303 - accuracy: 0.1058 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 63/100\n",
            "138/138 [==============================] - 1s 6ms/step - loss: 44.0188 - accuracy: 0.1033 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 64/100\n",
            "138/138 [==============================] - 1s 6ms/step - loss: 44.1796 - accuracy: 0.1084 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 65/100\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 43.7380 - accuracy: 0.1033 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 66/100\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 44.5237 - accuracy: 0.1030 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 67/100\n",
            "138/138 [==============================] - 1s 6ms/step - loss: 44.3300 - accuracy: 0.1073 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 68/100\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 44.2389 - accuracy: 0.1045 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 69/100\n",
            "138/138 [==============================] - 1s 8ms/step - loss: 44.0962 - accuracy: 0.1026 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 70/100\n",
            "138/138 [==============================] - 1s 9ms/step - loss: 44.1869 - accuracy: 0.1031 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 71/100\n",
            "138/138 [==============================] - 1s 9ms/step - loss: 44.1843 - accuracy: 0.1019 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 72/100\n",
            "138/138 [==============================] - 1s 8ms/step - loss: 44.0047 - accuracy: 0.1075 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 73/100\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 44.2048 - accuracy: 0.1039 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 74/100\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 44.4918 - accuracy: 0.1051 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 75/100\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 43.9557 - accuracy: 0.1093 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 76/100\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 44.1634 - accuracy: 0.1070 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 77/100\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 43.6690 - accuracy: 0.1075 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 78/100\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 44.2871 - accuracy: 0.1061 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 79/100\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 43.8081 - accuracy: 0.1108 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 80/100\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 43.9242 - accuracy: 0.1098 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 81/100\n",
            "138/138 [==============================] - 1s 6ms/step - loss: 44.0480 - accuracy: 0.1092 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 82/100\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 44.2789 - accuracy: 0.1070 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 83/100\n",
            "138/138 [==============================] - 1s 9ms/step - loss: 43.8560 - accuracy: 0.1072 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 84/100\n",
            "138/138 [==============================] - 1s 9ms/step - loss: 44.2700 - accuracy: 0.1084 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 85/100\n",
            "138/138 [==============================] - 1s 10ms/step - loss: 44.1853 - accuracy: 0.1096 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 86/100\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 44.1040 - accuracy: 0.1114 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 87/100\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 44.0616 - accuracy: 0.1072 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 88/100\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 44.2430 - accuracy: 0.1099 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 89/100\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 44.0405 - accuracy: 0.1113 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 90/100\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 44.1470 - accuracy: 0.1070 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 91/100\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 44.1295 - accuracy: 0.1087 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 92/100\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 44.2711 - accuracy: 0.1030 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 93/100\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 43.5119 - accuracy: 0.1073 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 94/100\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 44.1558 - accuracy: 0.1058 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 95/100\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 44.2198 - accuracy: 0.1058 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 96/100\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 44.1287 - accuracy: 0.1123 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 97/100\n",
            "138/138 [==============================] - 1s 10ms/step - loss: 44.2450 - accuracy: 0.1045 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 98/100\n",
            "138/138 [==============================] - 1s 9ms/step - loss: 44.1870 - accuracy: 0.1079 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 99/100\n",
            "138/138 [==============================] - 1s 9ms/step - loss: 44.0420 - accuracy: 0.1055 - val_loss: 30.9115 - val_accuracy: 0.1243\n",
            "Epoch 100/100\n",
            "138/138 [==============================] - 1s 7ms/step - loss: 44.2636 - accuracy: 0.1132 - val_loss: 30.9115 - val_accuracy: 0.1243\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "\n",
        "modelLSTM.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "historyLSTM = modelLSTM.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=32, epochs=100)\n"
      ],
      "metadata": {
        "id": "MdZB7koo7nKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "modelCNN.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "historyCNN = modelCNN.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=32, epochs=100)\n"
      ],
      "metadata": {
        "id": "K9FFhRn9KxzS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelNN.evaluate(X_test,y_test,verbose=0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YN58qYU3Kyd1",
        "outputId": "9ba2a694-c57b-4cf1-ef84-7786b59827e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[30.911455154418945, 0.12433768808841705]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelCNN.evaluate(X_test,y_test,verbose=0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHu5E_zhMCyH",
        "outputId": "32b5f5da-e744-4088-8841-38cf04fcfe6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7530624270439148, 0.8265630602836609]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelLSTM.evaluate(X_test,y_test,verbose=0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Td7Gx4y3MFbY",
        "outputId": "2449f5c1-ddc2-4e42-cc12-361203e0dcfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.4805271625518799, 0.714235246181488]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade scikit-learn\n"
      ],
      "metadata": {
        "id": "zAVKv_Ieulox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import minmax_scale, MinMaxScaler, LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "LN2-dMTrtKal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_pred_test = modelCNN.predict(X_test)\n",
        "print(classification_report(y_test, y_pred_test, digits=3))\n",
        "print('Test Accuracy = {:.4f}'.format(accuracy_score(y_test, y_pred_test)))\n",
        "fig, ax = plt.subplots(figsize=(6, 6))\n",
        "confusion_matrix(modelCNN, X_test, y_test, display_labels=[\"blues\", \"classical\", \"country\", \"disco\", \"hiphop\", \"jazz\", \"metal\", \"pop\", \"reggae\", \"rock\"], cmap=plt.cm.Blues, xticks_rotation=90, ax=ax)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        },
        "id": "uQcgdTjVtMkc",
        "outputId": "1bc8cb3e-4c24-48de-cea5-8a44dae5d1a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "89/89 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-1c48851b3c7c>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0my_pred_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodelCNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdigits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test Accuracy = {:.4f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelCNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"blues\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"classical\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"country\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"disco\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"hiphop\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"jazz\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"metal\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pop\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"reggae\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rock\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBlues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxticks_rotation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2308\u001b[0m     )\n\u001b[1;32m   2309\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2310\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2312\u001b[0m @validate_params(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     93\u001b[0m         raise ValueError(\n\u001b[1;32m     94\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[0;32m---> 95\u001b[0;31m                 \u001b[0mtype_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m             )\n\u001b[1;32m     97\u001b[0m         )\n",
            "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous-multioutput targets"
          ]
        }
      ]
    }
  ]
}